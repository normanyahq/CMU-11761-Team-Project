With the development of Language Technology, people have construct models to formally describe the natural language we are using in daily life.
Interestingly, some of the models have been powerful enough to generate fake articles that could even mix the false with the genuine.
Three MIT students developed a program called SCIgen\footnote{website: https://pdos.csail.mit.edu/archive/scigen/} that can automatically
generate an SCI article. They eventually fooled reviewers in several IEEE conferences with the generated articles. Therefore, a challenge is before
us: how can we tell the machine generated articles from human written ones. Finding such methods will not only avoid being fooled, but
can also help us build more powerful language model to make fun of the incompetent paper reviewers. 

In this project, we have extracted several features, and built several classification models to distinguish the fake generated by tri-gram models and 
 true articles. According to our experiment result , we have reached about 90\% accuracy in cross validation and development set. 